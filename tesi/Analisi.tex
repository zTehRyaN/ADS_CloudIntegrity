\section{Casi d'Uso}

%	Vengono qui descritti:
%	1. I vari casi d'uso funzione delle specifiche richieste per l'API
%	2. I vari casi d'uso con estensioni di una eventuale applicazione di persistenza all'API

% DIRE CHE L'UTILIZZO SARA' CONCORRENTE


\section{Modello di Dominio}

%	In base ai casi d'uso e, in qualche modo, ai requisiti sopra citati viene illustrato un analogo di modello di dominio.
	
	
\section{Skiplist}

%	In questa parte si parla della struttura dati utilizzata, studiata e realizzata. Ricordando che siamo all'interno della parte di analisi
%	è interessante richiamare a precedenti contestualizzazioni ed eventualmente fornire una generale descrizione della struttura che 
%	sia in grado di dare un'idea. Eventualmente fare analogia con alberi.
%
%	{Immagini}

	Prima di entrare nel dettaglio dell'analisi riguardante le strutture dati autenticate, si ritiene necessaria una preliminare analisi della struttura che sta alla base di tutto ciò: la skip list. In letteratura frequente è la scelta di strutture dati come alberi binari di ricerca bilanciati: si pensi agli alberi rosso-neri, una tra le più utilizzate implementazioni.
	
	La scelta di adozione di questa particolare struttura, sebbene risulti vincolo di progetto, rispecchia molte necessità richieste dall'utilizzatore. Di seguito se ne presentano le principali.
	
	La skiplist risulta essere più gestibile e adatta per quanto riguarda accessi e/o modifiche concorrenti. Infatti nel caso degli alberi rosso-neri il problema sussiste dal momento in cui le operazioni di modifica comportano sempre la necessità di bilanciamento della struttura. Questa operazione può interessare anche gran parte della struttura stessa, risultando talvolta anche largamente bloccante per altre eventuali operazioni effettuate in ambito concorrente. Altri utenti infatti, potrebbero voler accedere, in scrittura o in lettura, a nodi che devono ancora essere processati. Le performance di un albero rosso-nero, come detto una delle principali implementazioni di alberi di binari di ricerca, risulterebbero degradare linearmente per ogni nuovo utente concorrente. Realizzazioni più rigide di questa struttura comportano infatti lo stato bloccante su tutti i nodi della struttura durante il bilanciamento, e, nonostante esistano realizzazioni più rilassate, queste non hanno un impatto rilevante nel miglioramento delle performance (1)
	Letture e scritture in una skiplist risultano invece molto più localizzate e solo pochi nodi, quelli direttamente interessati, richiedono lo stato bloccante.
	
	La skip list, dunque, soddisfa la contemporanea necessità di avere una struttura dati ordinata e che sia thread-safe, cioè adatta ad un contesto concorrente.
	E' inoltre opportuno precisare da un lato il maggiore spazio richiesto dalle skiplist rispetto ad alberi bilanciati, in quanto necessitano, in media, del doppio dei puntatori per nodo, e dall'altro però la loro estrema facilita di implementazione.
	
	\subsection{Definizione}
	
%		Qui si procede con una più precisa e dettagliata definizione della struttura
%		
%		{dimostrazioni MIT}
%		{Immagini}

	Dopo averne brevemente motivato l'adozione, si procede con una più precisa definizione che possa aiutare il lettore a comprendere appieno il razionale retrostante questa struttura. 
	La skip list è una struttura dati probabilistica che permette veloci ricerche all'interno di una sequenza ordinata di elementi. Essa mantiene un insieme ordinato di $ n $ elementi in tempo $\mathcal{O}(log{}n)$.
	
	Prendendo ad esempio una lista semplice e non ordinata di elementi, si noti che l'operazione di ricerca di un elemento venga soddisfatta in tempo $\mathcal{O}(n)$. Questo vale anche per una lista ordinata di elementi. Questo tuttavia è vero nell'ipotesi in cui sia possibile accedere alla lista solamente tramite un puntatore verso l'inizio della stessa. Nell'ipotesi invece di accesso randomico a qualsiasi elemento, è possibile effettuare un'operazione di ricerca in tempo $\mathcal{O}(log{}n)$. Ebbene questa è l'idea retrostante.
	Tutto questo è reso possibile grazie ad una gerarchia di sottosequenze, organizzate su più livelli collegati tra loro. Lo sviluppo è in altezza e prevede che il livello più basso, detto $base list$ contenga tutti gli $ n $ elementi, mentre ogni livello superiore è composto da un sottoinsieme degli elementi del livello immediatamente sottostante. Le operazioni di ricerca iniziano dal livello con meno elementi, ovvero quello all'apice della struttura, e procedono per salti, in gergo 'skip', di nodo in nodo, fino a che non vengono trovati due elementi consecutivi, uno minore e uno maggiore o uguale all'elemento ricercato. A questo punto, grazie ai collegamenti inter-livello è possibile spostarsi sulla sottosequenza immediatamente inferiore e proseguire la ricerca. Questo procedimento è ripetuto fino a giungere alla sequenza completa di elementi, ovvero al livello più basso.
	Ogni livello inoltre, agli estremi, possiede due sentinelle, ovvero due nodi speciali, marcati con $\infty$ e -$\infty$. Questi formeranno due torri, che racchiudono a destra e a sinistra la struttura contenente gli elementi veri e propri. Si può dimostrare però che ciò non è sempre completamente necessario, ma si tratta più di rigorosità nella formulazione.
	Il nodo sentinella -$\infty$ della sequenza all'apice della struttura è detto $start node$ ed è il nodo di partenza per ogni operazione.
	
	Il principio secondo cui gli elementi sono saltati, e quindi indirettamente il principio secondo cui un elemento debba o meno essere presente anche nel livello immediatamente superiore, può essere randomico o deterministico. Il primo caso, di più frequente utilizzo, prevede una costruzione della struttura per strati. Il primo, contenente tutti gli $ n $ elementi è una normale lista doppiamente o singolarmente concatenata. Ogni livello superiore poi è costruito a partire da quello sottostante, dove però ogni elemento ha una certa probabilità, fissata a priori, di essere presente. Normalmente la probabilità fissata a priori è $ 1/2 $, a tal punto che in letteratura si parli spesso di 'Fair coin flip'.
	
	Prima di procedere con la descrizione dettagliata delle operazioni che fornisce, occorre introdurre ulteriore terminologia. Un nodo di un livello $ L_{i-1} $ contenente un elemento che non è presente al livello $ L_{i} $ è detto $ plateau $. Un nodo che non presenta queste caratteristiche è detto $ tower $. (2)
	
	Per comodità delle future analisi si è deciso di adottare una terminologia simile allo scritto di Goodrich e Tamassia (2), a cui ci si rifarà anceh nel successivo sottoparagrafo, in cui per ogni nodo $ v $ della sottosequenza $ L_{i} $, è detto $ elem(v) $ l'elemento memorizzato in $ v $. Inoltre è detto $ down(v) $ il nodo della sottosequenza $ L_{i-1} $ che memorizza lo stesso valore di $ v $, a meno che non si tratti della $base list$, poiché in questo caso $down(v) = \boldmath{null}$.
	Inoltre è detto $right(v)$ il nodo della sottosequenza $ L_{i} $ immediatamente alla destra di $v$, a meno che non si tratti di una sentinella di tipo $\infty$, per la quale $right(v) = \boldmath{null}$.
		
	\begin{figure}
		\centering
		\includegraphics[scale=0.6]{figure/skiplist.eps}
		\caption{Esempio di una Skip List}\label{fig:1}
	\end{figure}
		
	\subsection{Operazioni principali}
	
%		Rimanendo sullo stesso livello di dettaglio raggiunto dalla sottosezione di definizione, si prosegue con una dettagliata analisi
%		delle principali operazioni operabili su una skiplist. Trovandoci nella parte di analisi si evidenzi il collegamento tra le parti: qui la
%		funzione di questa sezione è di introdurre alla struttura di base, che sarà poi ampliata e utilizzata nei paragrafi successivi quando
%		si aggiungerà l'autenticazione.
%		
%		Potrebbero essere utili immagini e pseudocodice, ma qui siamo ancora parlando della struttura di base pertanto si tratta di apporti
%		alquanto standard e non personali. Potrebbe dunque essere superfluo l'inserimento di pseudo. Le immagini potrebbero essere usate
%		per illustrare più intuitivamente i vari algoritmi che magari prima sono descritti molto più formalmente.
%		{Immagini}
%		{Pseudo}

		Dopo aver introdotto a grandi linee il razionale alla base della skip list, si procede in questa sezione ad una più dettagliata enumerazione delle operazioni che supporta:
		\begin{itemize} 
			\item \textbf{Ricerca}: determina se un elemento è o meno presente nella skip list.
			\item \textbf{Inserimento}: inserisce un elemento.
			\item \textbf{Cancellazione}: elimina un elemento.
		\end{itemize} 
	
		\subsubsection{Ricerca}
			
			L'operazione di ricerca di un elemento $ x $ in una skip list inizia, come tutte le altre, dallo $start node$. La ricerca viene effettuata tramite l'alternanza di due azioni, $ hop forward $ e $ drop down $, che rappresentano rispettivamente il movimento verso destra o verso il basso all'interno della struttura. Esse sono ripetute, sotto determinate condizioni, fino a che la ricerca non sia terminata, indipendentemente dall'esito, che potrà essere positivo o negativo.
			
			La prima azione menzionata prevede movimenti verso destra fino a che non si raggiunge un nodo il cui valore sia il più grande minore o uguale a $ x $. La seconda azione invece consiste semplicemente in uno spostamento verticale, al nodo immediatamente sottostante, a condizione che questo esista.  In pseudocodice, i passi rilevanti delle due azioni, rispettivamente: 
			
			\begin{itemize}
			
			\item \textbf{Hop forward}:
				\begin{algorithm}[H]
					\While{elem(right(v)) < x}{
						v $\leftarrow$ right(v)\;
					}
				\end{algorithm}
			
			\item \textbf{Drop down}:
				\begin{algorithm}[H]
					\eIf{down(v)  != null}{
						v $\leftarrow$ down(v)\;
					}{
						end search\;
					}
				\end{algorithm}
			\end{itemize} 
			
			La ricerca consiste dunque in un $ hop forward $ e un $ drop down $, fintanto che risulti possibile effettuare $ dropdown $.  Con questa sequenza di passi si raggiungerà un nodo sulla $ base list $: se vale che $ elem(v) = x $ allora la skip list contiene l'elemento $ x $. Se questa condizione non risulta vera, allora il nodo raggiunto tramite questa sequenza di passi sarà il nodo sulla $ base list $ con il valore più grande minore di $ x $. Per costruzione $ right(v) $ è il nodo sulla $ base list $ il cui elemento è il più piccolo maggiore di $ x $.
			
			Il costo computazionale dell'operazione di ricerca è dato dalla somma dei costi di attraversamento di tutti i livelli. Tuttavia ogni livello, tranne il primo, subisce un attraversamento parziale, in quanto il nodo di partenza non è il primo nodo della sequenza.
			
			
			\begin{figure}
				\centering
				\includegraphics[scale=0.6]{figure/search-66.eps}
				\caption{\textbf{Ricerca dell'elemento 66} nella Skip List della figura \ref{fig:1}. I nodi visitati e i collegamenti attraversati sono evidenziati con linee più spesse. Si noti che la ricerca, fallimentare, dell'elemento 70 produrrebbe lo stesso risultato.}\label{fig:2}
			\end{figure}
			
			{EVENTUALE DIMOSTRAZIONE MIT}
			
			Considerando che il numero di livelli in una skip list con $ n $ elementi è, con alta probabilità\footnote{Un evento occorre con alta probabilità quando la sua probabilità dipende da un certo valore $ n $ e tende a 1 quando $ n $ tende a $\infty$}, pari a $\mathcal{O}(log{}n)$, è dimostrabile che il costo di ricerca è, con alta probabilità, pari a $\mathcal{O}(log{}n)$.
				
		\subsubsection{Inserimento}
		
			L'operazione di inserimento è sempre preceduta da una operazione di ricerca. Dunque per inserire un elemento $ x $, per prima cosa è effettuata una ricerca su $ x $, con l'unica differenza che ogni volta che viene effettuato un $ hop forward $ o un $ drop down $ rispetto al nodo corrente $ v $, viene aggiunto un elemento in una pila che registri il nodo corrente $ v $ e l'azione associata.
			Dal momento in cui l'elemento $ x $ non è presente, l'operazione di ricerca restituirà il nodo sulla $base list$ che dovrà essere immediatamente precedente al nodo da inserire. Dunque è inserito il nodo, memorizzato il valore $ x $. Dopodiché, nel caso di skip list randomiche, viene valutata l'altezza della torre, ovvero in quali livelli superiori dovrà essere presente l'elemento, tramite una sequenza di tiri di moneta simulati. Per ogni lancio di moneta, nel caso in cui il risultato sia testa, viene utilizzato la pila per ripercorrere il percorso a ritroso e ottenere la posizione, del livello superiore, in cui dovrà andare il nuovo nodo, tramite opportune operazioni di $ pop $. Il procedimento continua fino a che il risultato non sia croce. Nel caso in cui la torre dovesse superare l'altezza corrente della struttura, si aggiunge un nuovo livello alla struttura, compresi ovviamente i nuovi nodi sentinella.
			L'operazione di inserimento è, con alta probabilità, pari a $\mathcal{O}(log{}n)$.
		
		\subsubsection{Cancellazione}
		
			L'operazione di cancellazione di un elemento $ x $ prevede la ricerca di un elemento che sia minore di $ x $ ma maggiore di ogni altro elemento nella $base list$ che sia minore di $ x $. Come per l'operazione di inserimento, viene utilizzata una pila di supporto per tenere traccia dei passi effettuati dalla ricerca. Chiaramente, l'elemento immediatamente successivo al nodo restituito dall'operazione di ricerca, dovrà essere $ x $, poiché in caso contrario l'elemento da cancellare non sarebbe presente nella skip list, scenario di non successo, da segnalare con errore opportunamente.
			Dunque viene rimosso il nodo interessato, e tutti i nodi sulla stessa torre, ottenendone la posizione grazie ad opportune operazioni di $ pop $ dalla pila precedentemente riempita.
			Nel caso in cui la rimozione dovesse comportare un abbassamento globale della struttura, devono essere eliminati i nodi sentinella interessati.
			L'operazione di cancellazione è, con alta probabilità, pari a $\mathcal{O}(log{}n)$.
			
	
\section{Hashing Non-commutativo}
	
%	Qui si parla della tecnica di hashing commutativo

	Si ritiene necessario, a questo punto, introdurre una speciale classe di funzioni: le funzioni crittografiche di hash. Si tratta di algoritmi matematici che mappano, cioè fanno corrispondere, dati di lunghezza arbitraria, comunemente chiamati $ messaggi $, in un stringa binaria di dimensione fissa, detta $ valore di hash $. L'output prodotto è solitamente chiamato $ digest $. (4)
	L'hash di un messaggio $ m $ è denotato $ h(m) $ e varranno le seguenti proprietà:
	
	\begin{itemize}
		\item Per ogni $ m $ il calcolo di $ h(m) $ è efficiente;
		\item Dato un $ H $, è computazionalmente difficile trovare $ m $ tale che $ H = h(m) $;
		\item Dato $ h $, è computazionalmente difficile trovare un $ m \ne m^{'}$ tale che $ h(m) = h(m^{'}) $;
		\item Dato $ h $ e $ m $, è computazionalmente difficile trovare un $ m \ne m^{'} $, tale che $ h(m) = h(m^{'}) $. (5)
	\end{itemize}

	E' altrettanto vero che la funzione può essere applicata a due o più messaggi. Pertanto data una coppia di valori $ a $ e $ b $, sarà $ h(a,b) $ il digest prodotto dalla funzione di hash. Lo stesso è applicabile anche su triple, e più in generale su n-ple di lunghezza qualsiasi. Per effetture il digest di una sequenza $ (x_{1}, x_{2}, ... , x_{m}) $, dovrà essere effettuato il seguente calcolo: $ h(x_{1}, h(x_{2}, ... h(x_{m-2},h(x_{m-1},x_{m}))...)) $. (2)
	
		\subsection{Funzioni}
	
	%		Funzioni di hash, con eventuale breve richiamo alle loro differenze. Questo servirà a giustificare la resa parametrica
	%		nel codice e potrà servire ad introdurre la parte di analisi di prestazioni, nel caso di dettaglio dell'analisi computazionale
	%		(spazio e tempo) riguardo l'applicazione delle varie funzioni di hashing.

	\subsection{Resistenza a collisioni}
	
%		In questa sottosezione si approfondisce la caratteristica di resistenza a collisioni dell'hashing commutativo
%		con particolare attenzione all'utilità di questa caratteristica al nostro studio

		L'utilità di una funzione crittografica di hash all'interno di una struttura dati autenticata, di cui si parlerà più approfonditamente nel successivo paragrafo, è data dalla resistenza alle collisioni. Ovvero data una coppia di valori $ (a,b) $, risulta computazionalmente difficile trovare una coppia $ (c,d) \ne (a,b) $ tale per cui  $ h(a,b) = h(c,d) $. Infatti il costo computazionale richiesto per trovare una coppia di collisione $ (c,d) $ sarebbe troppo elevato anche per un supercomuter.
		La specifica di non commutatività della funzione di hash, serve a sottolineare l'esclusione della proprietà di commutatività che potrebbe essere inclusa per semplificare i processi di verifica effettuati dall'utente.
		In questo studio tuttavia essa non è permessa, causa vincoli di progetto, e dunque formalmente $ h(a,b) \ne h(b,a) $ per ogni $ a $ e $ b $.

	\subsection{Strutture dati autenticate}

% 		Introduzione su strutture dati autenticate. Magari breve, e mirata a far comprendere i sucessivi paragrafi

		Una struttura dati autenticata, abbreviato $ ADS $, è una struttura dati che è adatta a controlli sulla sua integrità, cosi come su porzioni di essa. Memorizza valori e associa una funzione crittografica di hash $ h $ con il suo contenuto. L'output prodotto da questa funzione è detto $root hash$ e possiede lunghezza finita. Tramite una ADS, dunque, un client può rilevare piccoli cambiamenti all'interno di un $ dataset $ anche molto grande, in maniera efficiente.
		La sua applicazione in ambiente cloud risulta particolarmente proficua in quanto generalmente permette di ottenere elevate garanzie su sicurezza, autenticazione e verifica di integrità dei dati. Tutto questo rispettando la dicotomia tra l'ambiente di storage locale, limitato ma fidato, $ trusted $, e l'ambiente cloud, virtualmente illimitato, ma non fidato. Il razionale alla base consiste nel memorizzare un grande $ dataset$ sul cloud, equipaggiato dunque con una ADS, e mantenere soltanto il root hash localmente.
		
		\begin{figure}
			\centering
			\includegraphics[scale=0.75]{figure/trusted-untrusted.eps}
			\caption{\textbf{Caso d'uso di ADS}: l'ADS può essere caricato sul cloud e applicato su uno $ storage $ regolare, mentre il client memorizza localmente il Root Hash. Lo storage non dovrebbe essere a conoscenza dell'ADS.}\label{fig:3}
		\end{figure}
		
		\begin{itemize}
			\item Le varie query, effettuate dal client, restituiranno oltre ai valori richiesti, anche una prova, detta $ Proof $. Tramite la proof ricevuta e il root hash locale, il client potrà verificare l'integrità del risultato della query.
			
			\begin{figure}
				\centering
				\includegraphics[scale=0.75]{figure/queryADS.eps}
				\caption{\textbf{Query}: il client effettua una query e riceve oltre al risultato atteso, una proof per quel risultato. Effettua dunque il calcolo localmente sulla proof e verifica se corrisponde al root hash locale.}\label{fig:4}
			\end{figure}
			
			\item Gli updates tuttavia, andranno a cambiare il $ dataset $ remoto, e dunque l'ADS presente sul cloud. Il client inoltre aggiorna il suo root hash locale con quello nuovo prodotto dall'ADS.
			
			\begin{figure}
				\centering
				\includegraphics[scale=0.75]{figure/updateADS.eps}
				\caption{\textbf{Update}: il client richiede al server la proof su un valore da aggiornare. Può, a questo punto, aggiornare il root hash locale e inviare il nuovo valore al server. Suo è, successivamente, il compito di aggiornare l'ADS, $ refresh $ in figura.}\label{fig:5}
			\end{figure}
		
		\end{itemize}
	
		Dunque, updates effettuati da un qualsiasi client, su un qualsiasi valore della struttura, si ripercuoteranno sul root hash della struttura, permettendo il rilevamento delle modifiche ad ogni altro client, in tutte le successive query.
		
		Le più diffuse implementazioni di strutture dati autenticate sono:
		
		\begin{itemize}
			\item Merkle Hash Tree (MHT);
			\item Skip list autenticate.
		\end{itemize}
	
		Il funzionamento di quest'ultima sarà approfondito nei successivi paragrafi.
	
\section{API}

%	{Analisi prettamente tecnologica}
%	
%	Qui, sulla base di quanto detto precedentemente, si inizia a mettere insieme le varie parti per descrivere più
%	nel dettaglio l'API. Già nella prima parte è stato introdotto a grandi linee il funzionamento. Qui viene ripreso e
%	approfondito, anche e sopratutto grazie alle sottosezioni successive. 
	
	\subsection{Skip List Autenticata}
	
%		MODELLO FUNZIONALE, rimandando a parte successiva 
%		
%		Qui si parla della skiplist autenticata, facendo chiaramente riferimento alla skiplist base, sia nella definizione,
%		sia nella descrizione delle operazioni

	Una skip list autentiticata, come detto, è una particolare implementazione di un ADS, che si basa su skip list, e sulla quale è applicata una funzione crittografica di hash $ h $. La struttura dunque aggiungerà alla funzione di memorizzare un insieme di valori, in maniera ordinata, le caratteristiche tipiche di un ADS. Ogni nodo conterrà un hash dei dati di alcuni altri nodi adiacenti. Intuitivamente, il suo hash potrebbe essere in funzione di $ w = right(v) $ e $ u = down(u) $. Questo schema confluirà nel root hash, ovvero nel $ digest $ dell'intera skip list, il quale sarà memorizzato nello $start node$.
	Il root hash, per definizione e per costruzione, sarà rigidamente dipendente sia dai valori di ogni nodo che dalla loro posizione reciproca. Da questo calcolo sono esclusi i nodi sentinella.
	
		\subsubsection{Schema hashing}
	
	%		In questa sottosezione ci si riallaccia alla sezione sull'Hashing non-commutativo e semplicemente
	%		si definisce la sua applicazione alla skiplist autenticata. Nella sezione sopra l'argomento è affrontato in maniera più
	%		teorica, preliminare, e isolata. Qui invece si sottolinea l'aspetto pratico sulla struttura dati.
	
		Il calcolo del root hash dunque è strettamente legato allo schema di hashing scelto, ovvero alla modalità secondo cui i singoli nodi calcolano il loro hash locale in funzione dei nodi adiacenti. Per questa analisi, si è deciso di seguire lo schema suggerito da Tamassia(2), con alcune piccole variazioni. 
		Sia $ f(v) $ la funzione di hash di ogni singolo nodo, allora varrà che:
		
		\begin{enumerate}
			\item Se $ u = null $, e cioè se il nodo $ v $ si trova sulla $ base list $:
				\begin{itemize}
					\item (a) Se $ w $ è un nodo $ tower $, allora $ f(v) = h(elem(v)) $.
					\item (b) Se $ w $ è un nodo $ plateau $, allora  $ f(v) = h(h(elem(v)), f(w)) $.
				\end{itemize}
			\item Se $ u \ne null $, e cioè se il nodo $ v $ \underline{non} si trova sulla $ base list $:
				\begin{itemize}
					\item (a) Se $ w $ è un nodo $ tower $, allora $ f(v) = f(u) $. 
					\item (b) Se $ w $ è un nodo $ plateau $, allora  $ f(v) = h(f(u), f(w)) $. 
				\end{itemize}
		\end{enumerate}
	
		\begin{figure}
			\centering
			\includegraphics[scale=0.6]{figure/hashFlow.eps}
			\caption{In alto a sinistra, lo $ start node $ ha il root hash. $ RH $, dipendente dai valori $ m_{n} $ e dal loro ordinamento sulla baselist.}\label{fig:6}
		\end{figure}
	
		\subsubsection{Operazioni}
		
%			Sezione analoga a quella sulla skiplist semplice. Ovviamente questa è sempre una parte di analisi pertanto le varie spiegazione saranno puramente concettuali,
%			algoritmiche e legate a formule, e non comprenderanno scelte di progettazione.

			In quanto ADS, la skip list autenticata offrirà due tipologie di operazione:
			
			\begin{itemize}
				\item \textbf{Update}, ovvero la possibilità di fare inserimenti o cancellazioni.
				\item \textbf{Query}, con la possibilità di ottenere un valore e verificare la sua integrità.
			\end{itemize}
			
	\subsubsection{Update}
	
%		In questa parte si parla della principale operazione di questa struttura, in funzione proprio dell'utilizzo che se ne fa
%		{Citazione del protocollo}

		{AGGIUNGERE CITAZIONE PROTOCOLLO E TESI GIANMARIA}

		In base a quanto osservabile dai casi d'uso, l'$ update $ è l'operazione di primaria importanza. Nel momento in cui si vuole modificare, aggiungere o cancellare un valore nello $ storage $, la skip list autenticata deve aggiornarsi internamente, proprio a causa di questa modifica. Questo è possibile tramite l'operazione di update. Il client dunque, interagento con la struttura, dovrà specificare il tipo di operazione da svolgere (modifica, aggiunta o cancellazione) e il valore diretto interessato. 
		A seguito dell'invocazione di questa operazione sull'ADS, i valori di hash dei singoli nodi devono essere aggiornati per riflettere il cambiamento che è avvenuto, e con essi il $ root hash $.
		Nel caso di inserimento o cancellazione, la prima parte di esecuzione dell'operazione è identica a quella di una skip list semplice. Successivamente all'aggiunta/cancellazione del nodo interessato, viene utilizzata la pila precedentemente costituita per aggiornare gli hash dei nodi. Saranno infatti solamente i nodi presenti nella pila, ed eventualmente i suoi vicini di destra, grazie allo schema di hashing precedentemente presentato, a dover essere aggiornati. Pertanto ripercorrendo a ritroso tramite operazioni di $ pop $ la pila, la struttura dovrà ricalcolare le varie $ f(v) $ di questi nodi e nel caso di inserimento, dei nodi costituenti la nuova torre.
		L'aggiunta in termini di costo computazionale dovuta a questa ulteriore operazione di aggiornamento degli hash, è proporzionale al numero di elementi presenti nella pila. Con alta probabilità l'operazione sarà eseguita in $\mathcal{O}(log{}n)$.
		
		[IMMAGINE CON DUE SKIPLIST PICCOLE AFFIANCATE IN CUI SI EVIDENZIA UN UPDATE DI MODIFICA CON FLUSSI]
					
	\subsection{Proof}
		
%		In questa sottosezione si parla del concetto di Proof, sia da un punto di vista concettuale, sottolineando la sua utilità
%		e riallacciandosi a ciò che è stato detto in parti precedenti, sia da un punto di vista pratico. La parte implementativa con
%		le varie scelte sarà affrontata nel capitolo dedicato al Progetto.
%		{Anche qui supporto di citazione del protocollo}

		{AGGIUNGERE CITAZIONE PROTOCOLLO E TESI GIANMARIA}

		Prima di analizzare l'operazione di query, è necessario soffermarsi sul concetto di $ proof $, sopra solo accennato. La proof non è altro che un insieme di $ step $ da percorrere, secondo un preciso schema che rispecchia lo schema di hashing presente nella struttura dati autenticata, per ottenere il $ root hash $. Essa è utilizzato per ottenere una prova, appunto, della validità di un particolare elemento restituito da una query. Infatti oltre a ricevere un generico valore $ x $, il client ottiene anche una $ Proof(x) $, e potrà dunque verificare localmente la corrispondenza tra il proprio root hash locale, $ trusted Root Hash $, e quello ottenibile seguendo l'opportuna serie di passi sulla proof ottenuta, $ untrusted Root Hash $.
		
		[IMMAGINE DI UNA SKIPLIST SENZA FLUSSI DOVE E' EVIDENZIATA LA PROOF PER UN DETERMINATO VALORE]
 		
	\subsection{Query e Verifica}
	
%		Sezione in cui semplicemente si speiga come avviene una query e come è effettuata la verifica tramite la proof precedentemente descritta
%		{Citazione di protocollo}
%		{Schemi}

		{AGGIUNGERE CITAZIONE PROTOCOLLO E TESI GIANMARIA}
	
		Analizzato il concetto di $ proof $ è possibile ora inserirlo nel più ampio contesto di una query. Un client, a seguito dell'esecuzione di una query su un determinato valore $ x $, otterrà una $ Proof(x) $ per quel determinato valore. Il client, che memorizza localmente il $ root hash $ di struttura, ripercorrerà gli $ step $ opportuni sulla proof, grazie alla conoscenza della particolare funzione crittografica di hash $ h $ correntemente attiva sull'ADS. (Deve cioè effettuare operazioni di hash, nel dato ordine, di tutta una sequenza di hash.) Otterrà dunque il $ root hash $ presente sul cloud e potrà verificare che questo corrisponda a quello locale. Nel caso in cui questo non accada, vorrà dire che l'integrità del valore ottenuto non è garantita, in quando sono state effettuate delle modifiche sulla struttura, ovvero sul $ dataset $. 
			
		[IMMAGINE CON UNA SKIPLIST DA UN LATO E DALL'ALTRO IL RISULTATO DI UNA QUERY OVVERO IL VALORE E LA PROOF, DOVE VIENE FATTO VEDERE IL CHECK SU UGUAGLIANZA DEI ROOTHASH]
	
\section{Persistenza}

%	{Analisi prettamente relativa a studio teorico}
%	Qui si inizia a parlare approfonditamente del problema della persistenza approfondendo come si lega all'API. 

	\subsection{Modello Funzionale}
	
%	Giustificazione dell'adozione del modello valore. Prima viene giustificata nell'ambito della concorrenza, cioè dell'utilizzo (Thread Safety) ora anche
%	per quanto riguarda il modello funzionale. Per le strutture dati viene inoltre spiegato in termini molto precisi il fatto che viene salvata in persistenaza solo la struttura  ADS.
%	E si sottolinea il collegamento tra modello funzionale e possibilità di ovviare alla alta complessità computazionale spaziale del modelli funzionali.
